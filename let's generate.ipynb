{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl \n",
    "from pytorch_lightning import Trainer, LightningDataModule, LightningModule\n",
    "import torchdyn \n",
    "from torchdyn.core import NeuralODE\n",
    "\n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeData(Dataset):\n",
    "    def __init__(self, path, inpshape=(28, 36), outshape=(224, 288)):\n",
    "        super(GenerativeData, self).__init__()\n",
    "        self.path = path \n",
    "        self.inpshape = inpshape\n",
    "        self.outshape = outshape\n",
    "        self.inpimg, self.outimg = self.datareader()\n",
    "\n",
    "    def preprocess(self, image, imagesize):\n",
    "        process = T.Compose([T.ToTensor(), \n",
    "                             T.Resize(imagesize),\n",
    "                             T.Normalize(mean=(0.5, 0.5, 0.5), std=(1, 1, 1))])\n",
    "        return process(image)\n",
    "\n",
    "    def datareader(self):\n",
    "        X = []\n",
    "        Y = []\n",
    "        files = os.listdir(self.path)\n",
    "        for c, file in enumerate(files):\n",
    "            image = cv2.imread(self.path+file)\n",
    "            X.append(self.preprocess(image, self.inpshape))\n",
    "            Y.append(self.preprocess(image, self.outshape))\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inpimg)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inpimg = self.inpimg[idx]\n",
    "        outimg = self.outimg[idx]\n",
    "        return {\"inputs\": inpimg, \"outputs\": outimg}             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\suyash\\Downloads\\SeaGAN\\seacreature_images_transformed\\seacreature_images_transformed/'\n",
    "dataset = GenerativeData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, num:int, infilter:int, outfilter:int, kernel:int, moment:float=0.9, alpha:float=0.1):\n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "        self.conv = nn.ModuleList([nn.Conv2d(infilter, outfilter, kernel)])\n",
    "        self.norm = nn.ModuleList([nn.BatchNorm2d(outfilter, momentum=moment)])\n",
    "        self.pad  = nn.ZeroPad2d(int((kernel-1)//2))\n",
    "        self.act = nn.LeakyReLU(alpha)\n",
    "        self.pooling = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        for _ in range(num-1):\n",
    "            self.conv.append(nn.Conv2d(outfilter, outfilter, kernel))\n",
    "            self.norm.append(nn.BatchNorm2d(outfilter, momentum=moment))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, norm in zip(self.conv, self.norm):\n",
    "            x = self.act(norm(conv(self.pad(x))))\n",
    "        return self.pooling(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num:list=[2, 2, 2, 2], filter:int=64, start_kernel:int=7, kernel:int=3, \n",
    "                 moment:float=0.9, alpha:float=0.1, dense:int=256, gf:float=2.0, drop:float=0.2):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.convblock = nn.ModuleList([DiscriminatorBlock(1, filter, filter*gf, start_kernel, moment, alpha)])\n",
    "        for n in num:\n",
    "            filter = filter*gf\n",
    "            self.convblock.append(DiscriminatorBlock(n, filter, filter*gf, kernel, moment, alpha))\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.dense = nn.Linear(filter*gf, dense)\n",
    "        self.final = nn.Linear(dense, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for convblock in self.convblock:\n",
    "            x = convblock(x)\n",
    "        x = self.flat(self.pool(x))\n",
    "        x = F.relu(self.dense(x))\n",
    "        return F.softmax(self.final(x), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, num:int, infilter:int, outfilter:int, kernel:int, moment:float=0.9, alpha:float=0.1, end=False):\n",
    "        super(GeneratorBlock, self).__init__()\n",
    "        self.conv = nn.ModuleList([nn.Conv2d(infilter, outfilter, kernel)])\n",
    "        self.norm = nn.ModuleList([nn.BatchNorm2d(outfilter, momentum=moment)])\n",
    "        self.pad  = nn.ZeroPad2d(int((kernel-1)//2))\n",
    "        self.act = nn.LeakyReLU(alpha)\n",
    "        self.pooling = nn.MaxUnpool2d(2, 2)\n",
    "        self.end = end\n",
    "        \n",
    "        for _ in range(num-1):\n",
    "            self.conv.append(nn.Conv2d(outfilter, outfilter, kernel))\n",
    "            self.norm.append(nn.BatchNorm2d(outfilter, momentum=moment))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, norm in zip(self.conv, self.norm):\n",
    "            x = self.act(norm(conv(self.pad(x))))\n",
    "        if not self.end:\n",
    "            return self.pooling(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num:list=[3, 3, 3], filter:int=64, start_kernel:int=7, kernel:int=3, \n",
    "                 moment:float=0.9, alpha:float=0.1, dense:int=256, gf:float=2.0, drop:float=0.2):\n",
    "        super(Generator, self).__init__()\n",
    "        self.convblock = nn.ModuleList([])\n",
    "        for n in num:\n",
    "            filter = filter*gf\n",
    "            self.convblock.append(GeneratorBlock(n, filter, filter*gf, kernel, moment, alpha))\n",
    "\n",
    "        self.genfinal = GeneratorBlock(1, filter*gf, 3, 3, moment, alpha, end=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for convblock in self.convblock:\n",
    "            x = convblock(x)\n",
    "        return self.genfinal(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(nn.LightningModule):\n",
    "    def __init__(self, datatset, batchsize):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "        self.batchsize = batchsize\n",
    "        self.dataset = dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
